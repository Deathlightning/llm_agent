cmake >= 3.21
ninja  # For faster builds.
psutil
sentencepiece  # Required for LLaMA tokenizer.
numpy < 2.0.0
requests
tqdm
py-cpuinfo
transformers >= 4.42.0  # Required for Gemma 2 and for additional chat template parameters.
tokenizers >= 0.19.1  # Required for Llama 3.
fastapi
aiohttp
openai
uvicorn[standard]
pydantic >= 2.0  # Required for OpenAI server.
pillow  # Required for image processing
prometheus_client >= 0.18.0
prometheus-fastapi-instrumentator >= 7.0.0
tiktoken >= 0.6.0  # Required for DBRX tokenizer
lm-format-enforcer == 0.10.1
outlines >= 0.0.43 # Requires torch >= 2.1.0
typing_extensions
filelock >= 3.10.4 # filelock starts to support `mode` argument from 3.10.4

ray >= 2.9
nvidia-ml-py # for pynvml package
torch == 2.3.0
# These must be updated alongside torch
torchvision == 0.18.0   # Required for phi3v processor, also see https://github.com/pytorch/vision?tab=readme-ov-file#installation for corresponding version
xformers == 0.0.26.post1  # Requires PyTorch 2.3.0
vllm-flash-attn == 2.5.9  # Requires PyTorch 2.3.0
pyautogen==0.23.2